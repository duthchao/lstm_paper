{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopword: Package u'stopword' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(u'stopword')\n",
    "nltk.download(u'wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from __future__ import print_function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from datetime import datetime\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "np.random.seed(1337) \n",
    "\n",
    "class DFtransformer(object):\n",
    "    def __init__(self,min_df=5):\n",
    "        self.min_df = min_df\n",
    "        self.Vocab = defaultdict(int)\n",
    "        self.Vocab_ = {}\n",
    "    def fit(self,sentence_lst):\n",
    "        for sentence in sentence_lst:\n",
    "            for word in sentence.split():\n",
    "                self.Vocab[word] += 1\n",
    "        print (\"origenal vocab:\",len(self.Vocab))\n",
    "        self.Vocab = {k:v for k,v in self.Vocab.items() if self.Vocab[k]>=self.min_df}   \n",
    "        i = 1\n",
    "        for k in self.Vocab:\n",
    "            self.Vocab_[k] = i\n",
    "            i += 1\n",
    "        print (\"transformed vocab:\",len(self.Vocab))\n",
    "        \n",
    "    def tranform(self,sentence_lst):\n",
    "        ret_s_lst = []\n",
    "        for s in sentence_lst:\n",
    "            ret_s = np.array([self.Vocab_[w] for w in s.split() if w in self.Vocab_])\n",
    "            #print ret_s\n",
    "            ret_s_lst.append(ret_s)\n",
    "        return np.array(ret_s_lst)\n",
    "\n",
    "toker = TreebankWordTokenizer()\n",
    "lemmer = wordnet.WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stop_w = set(stopwords.words('english'))\n",
    "# w2v_model =  '../../../../media/lhc/B2DA42D1DA429191/word2vec_data/GoogleNews-vectors-negative300.bin'\n",
    "# embedder = Word2Vec.load_word2vec_format(w2v_model,binary=True)\n",
    "\n",
    "def str_lem(s):\n",
    "    s = s.lower()\n",
    "    s = (\" \").join([z for z in re.findall('\\w{2,}',s) if z not in stop_w])\n",
    "    s = (\" \").join([lemmer.lemmatize(z) for z in s.split(\" \")])\n",
    "    return s\n",
    "def str_stem(s):\n",
    "    s = s.lower()\n",
    "    s = (\" \").join([z for z in re.findall('\\w{2,}',s) if z not in stop_w])\n",
    "    s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    return s\n",
    "def apply_text_preprocessor(columns,str_process):\n",
    "    rets = []\n",
    "    for i,row in enumerate(columns,start=1):\n",
    "#         if i%10000==0:\n",
    "#             print i,\n",
    "        rets.append(str_process(row))\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title_stem</th>\n",
       "      <th>title_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.012007</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>US STOCKS-Dow, S&amp;P 500 end at record highs aga...</td>\n",
       "      <td>A</td>\n",
       "      <td>us stock dow 500 end record high googl jump</td>\n",
       "      <td>u stock dow 500 end record high google jump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>-0.016690</td>\n",
       "      <td>-0.004375</td>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>Hollande, Merkel urge Putin to broker Ukraine ...</td>\n",
       "      <td>A</td>\n",
       "      <td>holland merkel urg putin broker ukrain ceasefir</td>\n",
       "      <td>hollande merkel urge putin broker ukraine ceas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>-0.010669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>Agilent beats 4Q profit forecasts</td>\n",
       "      <td>A</td>\n",
       "      <td>agil beat 4q profit forecast</td>\n",
       "      <td>agilent beat 4q profit forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>-0.009389</td>\n",
       "      <td>0.019441</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>Agilent matches Street 1Q forecasts</td>\n",
       "      <td>A</td>\n",
       "      <td>agil match street 1q forecast</td>\n",
       "      <td>agilent match street 1q forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>-0.010305</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>Mallinckrodt PLC (MNK), Pfizer Inc. (PFE): Hea...</td>\n",
       "      <td>A</td>\n",
       "      <td>mallinckrodt plc mnk pfizer inc pfe healthcor ...</td>\n",
       "      <td>mallinckrodt plc mnk pfizer inc pfe healthcor ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        d1        d2        d3        date  \\\n",
       "0  2014-05-15  0.009910 -0.001090 -0.012007  2014-05-15   \n",
       "1  2014-07-03 -0.005816 -0.016690 -0.004375  2014-07-03   \n",
       "2  2014-11-17 -0.010669  0.000000  0.011274  2014-11-17   \n",
       "3  2015-02-17  0.025173 -0.009389  0.019441  2015-02-17   \n",
       "4  2015-03-02 -0.010305 -0.006152  0.005238  2015-03-02   \n",
       "\n",
       "                                               title ticker  \\\n",
       "0  US STOCKS-Dow, S&P 500 end at record highs aga...      A   \n",
       "1  Hollande, Merkel urge Putin to broker Ukraine ...      A   \n",
       "2                  Agilent beats 4Q profit forecasts      A   \n",
       "3                Agilent matches Street 1Q forecasts      A   \n",
       "4  Mallinckrodt PLC (MNK), Pfizer Inc. (PFE): Hea...      A   \n",
       "\n",
       "                                          title_stem  \\\n",
       "0        us stock dow 500 end record high googl jump   \n",
       "1    holland merkel urg putin broker ukrain ceasefir   \n",
       "2                       agil beat 4q profit forecast   \n",
       "3                      agil match street 1q forecast   \n",
       "4  mallinckrodt plc mnk pfizer inc pfe healthcor ...   \n",
       "\n",
       "                                           title_lem  \n",
       "0        u stock dow 500 end record high google jump  \n",
       "1  hollande merkel urge putin broker ukraine ceas...  \n",
       "2                    agilent beat 4q profit forecast  \n",
       "3                   agilent match street 1q forecast  \n",
       "4  mallinckrodt plc mnk pfizer inc pfe healthcor ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = './data/news_o1.csv'\n",
    "df_all = pd.read_csv(fin,encoding='utf8')\n",
    "#df_all = df_all[df_all.target.notnull()]\n",
    "df_all['title_stem'] = apply_text_preprocessor(df_all['title'],str_stem)\n",
    "df_all['title_lem'] = apply_text_preprocessor(df_all['title'],str_lem)\n",
    "df_all.head()\n",
    "#test\n",
    "# df_ = df_all[df_all['ticker'] == 'AAPL']\n",
    "# df_.index = df_['date'].map(pd.Timestamp)\n",
    "# df_['2016-04-25':'2016-04-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origenal vocab: 40593\n",
      "transformed vocab: 15942\n"
     ]
    }
   ],
   "source": [
    "target = 'd1'\n",
    "\n",
    "df = df_all[df_all[target].notnull()]\n",
    "dftransformer =  DFtransformer(min_df=5)\n",
    "dftransformer.fit(df['title_lem'])\n",
    "seq_lst = dftransformer.tranform(df['title_lem'])\n",
    "maxlen = 20\n",
    "X = sequence.pad_sequences(seq_lst,maxlen=maxlen)\n",
    "y = (df[target].values>0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (242941, 20)\n",
      "X_test shape: (60736, 20)\n",
      "X_train[0]: [    0     0     0     0     0     0     0     0     0     0     0 10321\n",
      " 13493 12780 13735  5949 13172 15240 14262  2430]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)            (None, 20, 128)     2040704     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 128)         131584      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 1)           129         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 1)           0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2172417\n",
      "____________________________________________________________________________________________________\n",
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "  9440/242941 [>.............................] - ETA: 444s - loss: 0.6933 - acc: 0.5136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9985ddfc4618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n\u001b[1;32m---> 44\u001b[1;33m           validation_data=(X_test, y_test),verbose=1)\n\u001b[0m\u001b[0;32m     45\u001b[0m score, acc = model.evaluate(X_train, y_train,verbose=1,\n\u001b[0;32m     46\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m    951\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = 15942 + 1\n",
    "batch_size = 32\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303677L, 20L)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322713L,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(u'stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
