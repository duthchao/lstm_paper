{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopword: Package u'stopword' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(u'wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from __future__ import print_function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from datetime import datetime\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "np.random.seed(1337) \n",
    "\n",
    "class DFtransformer(object):\n",
    "    def __init__(self,min_df=5):\n",
    "        self.min_df = min_df\n",
    "        self.Vocab = defaultdict(int)\n",
    "        self.Vocab_ = {}\n",
    "    def fit(self,sentence_lst):\n",
    "        for sentence in sentence_lst:\n",
    "            for word in sentence.split():\n",
    "                self.Vocab[word] += 1\n",
    "        print (\"origenal vocab:\",len(self.Vocab))\n",
    "        self.Vocab = {k:v for k,v in self.Vocab.items() if self.Vocab[k]>=self.min_df}   \n",
    "        i = 1\n",
    "        for k in self.Vocab:\n",
    "            self.Vocab_[k] = i\n",
    "            i += 1\n",
    "        print (\"transformed vocab:\",len(self.Vocab))\n",
    "        \n",
    "    def tranform(self,sentence_lst):\n",
    "        ret_s_lst = []\n",
    "        for s in sentence_lst:\n",
    "            ret_s = np.array([self.Vocab_[w] for w in s.split() if w in self.Vocab_])\n",
    "            #print ret_s\n",
    "            ret_s_lst.append(ret_s)\n",
    "        return np.array(ret_s_lst)\n",
    "\n",
    "toker = TreebankWordTokenizer()\n",
    "lemmer = wordnet.WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stop_w = set(stopwords.words('english'))\n",
    "# w2v_model =  '../../../../media/lhc/B2DA42D1DA429191/word2vec_data/GoogleNews-vectors-negative300.bin'\n",
    "# embedder = Word2Vec.load_word2vec_format(w2v_model,binary=True)\n",
    "\n",
    "def str_lem(s):\n",
    "    s = s.lower()\n",
    "    s = (\" \").join([z for z in re.findall('\\w{2,}',s) if z not in stop_w])\n",
    "    s = (\" \").join([lemmer.lemmatize(z) for z in s.split(\" \")])\n",
    "    return s\n",
    "def str_stem(s):\n",
    "    s = s.lower()\n",
    "    s = (\" \").join([z for z in re.findall('\\w{2,}',s) if z not in stop_w])\n",
    "    s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    return s\n",
    "def apply_text_preprocessor(columns,str_process):\n",
    "    rets = []\n",
    "    for i,row in enumerate(columns,start=1):\n",
    "#         if i%10000==0:\n",
    "#             print i,\n",
    "        rets.append(str_process(row))\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title_stem</th>\n",
       "      <th>title_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.012007</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>US STOCKS-Dow, S&amp;P 500 end at record highs aga...</td>\n",
       "      <td>A</td>\n",
       "      <td>us stock dow 500 end record high googl jump</td>\n",
       "      <td>u stock dow 500 end record high google jump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>-0.016690</td>\n",
       "      <td>-0.004375</td>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>Hollande, Merkel urge Putin to broker Ukraine ...</td>\n",
       "      <td>A</td>\n",
       "      <td>holland merkel urg putin broker ukrain ceasefir</td>\n",
       "      <td>hollande merkel urge putin broker ukraine ceas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>-0.010669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>Agilent beats 4Q profit forecasts</td>\n",
       "      <td>A</td>\n",
       "      <td>agil beat 4q profit forecast</td>\n",
       "      <td>agilent beat 4q profit forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>-0.009389</td>\n",
       "      <td>0.019441</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>Agilent matches Street 1Q forecasts</td>\n",
       "      <td>A</td>\n",
       "      <td>agil match street 1q forecast</td>\n",
       "      <td>agilent match street 1q forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>-0.010305</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>Mallinckrodt PLC (MNK), Pfizer Inc. (PFE): Hea...</td>\n",
       "      <td>A</td>\n",
       "      <td>mallinckrodt plc mnk pfizer inc pfe healthcor ...</td>\n",
       "      <td>mallinckrodt plc mnk pfizer inc pfe healthcor ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        d1        d2        d3        date  \\\n",
       "0  2014-05-15  0.009910 -0.001090 -0.012007  2014-05-15   \n",
       "1  2014-07-03 -0.005816 -0.016690 -0.004375  2014-07-03   \n",
       "2  2014-11-17 -0.010669  0.000000  0.011274  2014-11-17   \n",
       "3  2015-02-17  0.025173 -0.009389  0.019441  2015-02-17   \n",
       "4  2015-03-02 -0.010305 -0.006152  0.005238  2015-03-02   \n",
       "\n",
       "                                               title ticker  \\\n",
       "0  US STOCKS-Dow, S&P 500 end at record highs aga...      A   \n",
       "1  Hollande, Merkel urge Putin to broker Ukraine ...      A   \n",
       "2                  Agilent beats 4Q profit forecasts      A   \n",
       "3                Agilent matches Street 1Q forecasts      A   \n",
       "4  Mallinckrodt PLC (MNK), Pfizer Inc. (PFE): Hea...      A   \n",
       "\n",
       "                                          title_stem  \\\n",
       "0        us stock dow 500 end record high googl jump   \n",
       "1    holland merkel urg putin broker ukrain ceasefir   \n",
       "2                       agil beat 4q profit forecast   \n",
       "3                      agil match street 1q forecast   \n",
       "4  mallinckrodt plc mnk pfizer inc pfe healthcor ...   \n",
       "\n",
       "                                           title_lem  \n",
       "0        u stock dow 500 end record high google jump  \n",
       "1  hollande merkel urge putin broker ukraine ceas...  \n",
       "2                    agilent beat 4q profit forecast  \n",
       "3                   agilent match street 1q forecast  \n",
       "4  mallinckrodt plc mnk pfizer inc pfe healthcor ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = './data/news_o1.csv'\n",
    "df_all = pd.read_csv(fin,encoding='utf8')\n",
    "#df_all = df_all[df_all.target.notnull()]\n",
    "df_all['title_stem'] = apply_text_preprocessor(df_all['title'],str_stem)\n",
    "df_all['title_lem'] = apply_text_preprocessor(df_all['title'],str_lem)\n",
    "df_all.head()\n",
    "#test\n",
    "# df_ = df_all[df_all['ticker'] == 'AAPL']\n",
    "# df_.index = df_['date'].map(pd.Timestamp)\n",
    "# df_['2016-04-25':'2016-04-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origenal vocab: 40593\n",
      "transformed vocab: 15942\n"
     ]
    }
   ],
   "source": [
    "target = 'd1'\n",
    "\n",
    "df = df_all[df_all[target].notnull()]\n",
    "dftransformer =  DFtransformer(min_df=5)\n",
    "dftransformer.fit(df['title_lem'])\n",
    "seq_lst = dftransformer.tranform(df['title_lem'])\n",
    "maxlen = 20\n",
    "X = sequence.pad_sequences(seq_lst,maxlen=maxlen)\n",
    "y = (df[target].values>0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (242941, 20)\n",
      "X_test shape: (60736, 20)\n",
      "X_train[0]: [    0     0     0     0     0     0     0     0     0     0     0 10321\n",
      " 13493 12780 13735  5949 13172 15240 14262  2430]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 20, 128)       2040704     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 128)           131584      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             129         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2172417\n",
      "____________________________________________________________________________________________________\n",
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "204448/242941 [========================>.....] - ETA: 44s - loss: 0.6901 - acc: 0.5253"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9985ddfc4618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n\u001b[1;32m---> 44\u001b[1;33m           validation_data=(X_test, y_test),verbose=1)\n\u001b[0m\u001b[0;32m     45\u001b[0m score, acc = model.evaluate(X_train, y_train,verbose=1,\n\u001b[0;32m     46\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1080\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    799\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = 15942 + 1\n",
    "batch_size = 32\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (242941, 20)\n",
      "X_test shape: (60736, 20)\n",
      "X_train[0]: [    0     0     0     0     0     0     0     0     0     0     0 10321\n",
      " 13493 12780 13735  5949 13172 15240 14262  2430]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 20, 128)       2040704     embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 128)           131584      embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             129         lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2172417\n",
      "____________________________________________________________________________________________________\n",
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6899 - acc: 0.5260 - val_loss: 0.6855 - val_acc: 0.5441\n",
      "Epoch 2/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6754 - acc: 0.5689 - val_loss: 0.6825 - val_acc: 0.5514\n",
      "Epoch 3/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6612 - acc: 0.5917 - val_loss: 0.6822 - val_acc: 0.5554\n",
      "Epoch 4/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6478 - acc: 0.6065 - val_loss: 0.6857 - val_acc: 0.5563\n",
      "Epoch 5/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6355 - acc: 0.6167 - val_loss: 0.6887 - val_acc: 0.5603\n",
      "Epoch 6/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6247 - acc: 0.6253 - val_loss: 0.6936 - val_acc: 0.5594\n",
      "Epoch 7/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6155 - acc: 0.6322 - val_loss: 0.7063 - val_acc: 0.5596\n",
      "Epoch 8/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.6072 - acc: 0.6376 - val_loss: 0.7116 - val_acc: 0.5635\n",
      "Epoch 9/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.5992 - acc: 0.6436 - val_loss: 0.7133 - val_acc: 0.5619\n",
      "Epoch 10/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.5934 - acc: 0.6474 - val_loss: 0.7280 - val_acc: 0.5646\n",
      "Epoch 11/15\n",
      "242941/242941 [==============================] - 38s - loss: 0.5854 - acc: 0.6548 - val_loss: 0.7325 - val_acc: 0.5638\n",
      "Epoch 12/15\n",
      "235000/242941 [============================>.] - ETA: 1s - loss: 0.5791 - acc: 0.6598"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ed00b7810fa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n\u001b[1;32m---> 44\u001b[1;33m           validation_data=(X_test, y_test),verbose=1)\n\u001b[0m\u001b[0;32m     45\u001b[0m score, acc = model.evaluate(X_train, y_train,verbose=1,\n\u001b[0;32m     46\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1080\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    799\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = 15942 + 1\n",
    "batch_size = 1000\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (242941, 20)\n",
      "X_test shape: (60736, 20)\n",
      "X_train[0]: [    0     0     0     0     0     0     0     0     0     0     0 10321\n",
      " 13493 12780 13735  5949 13172 15240 14262  2430]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 20, 128)       2040704     embedding_input_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 128)           131584      embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             129         lstm_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 1)             0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2172417\n",
      "____________________________________________________________________________________________________\n",
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6904 - acc: 0.5245 - val_loss: 0.6861 - val_acc: 0.5406\n",
      "Epoch 2/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6780 - acc: 0.5644 - val_loss: 0.6833 - val_acc: 0.5509\n",
      "Epoch 3/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6667 - acc: 0.5841 - val_loss: 0.6828 - val_acc: 0.5536\n",
      "Epoch 4/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6566 - acc: 0.5972 - val_loss: 0.6838 - val_acc: 0.5548\n",
      "Epoch 5/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6492 - acc: 0.6064 - val_loss: 0.6863 - val_acc: 0.5548\n",
      "Epoch 6/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6422 - acc: 0.6128 - val_loss: 0.6875 - val_acc: 0.5565\n",
      "Epoch 7/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6354 - acc: 0.6171 - val_loss: 0.6900 - val_acc: 0.5572\n",
      "Epoch 8/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6283 - acc: 0.6225 - val_loss: 0.6980 - val_acc: 0.5580\n",
      "Epoch 9/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6227 - acc: 0.6275 - val_loss: 0.6987 - val_acc: 0.5575\n",
      "Epoch 10/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6180 - acc: 0.6298 - val_loss: 0.6998 - val_acc: 0.5581\n",
      "Epoch 11/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6126 - acc: 0.6337 - val_loss: 0.7085 - val_acc: 0.5600\n",
      "Epoch 12/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6078 - acc: 0.6372 - val_loss: 0.7158 - val_acc: 0.5589\n",
      "Epoch 13/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.6034 - acc: 0.6399 - val_loss: 0.7121 - val_acc: 0.5601\n",
      "Epoch 14/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.5984 - acc: 0.6444 - val_loss: 0.7307 - val_acc: 0.5616\n",
      "Epoch 15/15\n",
      "242941/242941 [==============================] - 15s - loss: 0.5941 - acc: 0.6476 - val_loss: 0.7297 - val_acc: 0.5609\n",
      "242941/242941 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "max_features = 15942 + 1\n",
    "batch_size = 3200\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2, consume_less='gpu'))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (242941, 20)\n",
      "X_test shape: (60736, 20)\n",
      "X_train[0]: [    0     0     0     0     0     0     0     0     0     0     0 10321\n",
      " 13493 12780 13735  5949 13172 15240 14262  2430]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 20, 256)       4081408     embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, 128)           197120      embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             129         lstm_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1)             0           dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4278657\n",
      "____________________________________________________________________________________________________\n",
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6903 - acc: 0.5257 - val_loss: 0.6860 - val_acc: 0.5438\n",
      "Epoch 2/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6770 - acc: 0.5672 - val_loss: 0.6833 - val_acc: 0.5483\n",
      "Epoch 3/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6651 - acc: 0.5860 - val_loss: 0.6843 - val_acc: 0.5527\n",
      "Epoch 4/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6554 - acc: 0.5984 - val_loss: 0.6855 - val_acc: 0.5542\n",
      "Epoch 5/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6474 - acc: 0.6057 - val_loss: 0.6866 - val_acc: 0.5559\n",
      "Epoch 6/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6379 - acc: 0.6147 - val_loss: 0.6896 - val_acc: 0.5569\n",
      "Epoch 7/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6299 - acc: 0.6204 - val_loss: 0.6944 - val_acc: 0.5581\n",
      "Epoch 8/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6224 - acc: 0.6259 - val_loss: 0.6964 - val_acc: 0.5583\n",
      "Epoch 9/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6162 - acc: 0.6314 - val_loss: 0.7033 - val_acc: 0.5600\n",
      "Epoch 10/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6088 - acc: 0.6365 - val_loss: 0.7172 - val_acc: 0.5615\n",
      "Epoch 11/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.6034 - acc: 0.6388 - val_loss: 0.7139 - val_acc: 0.5621\n",
      "Epoch 12/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.5977 - acc: 0.6422 - val_loss: 0.7215 - val_acc: 0.5629\n",
      "Epoch 13/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.5923 - acc: 0.6483 - val_loss: 0.7315 - val_acc: 0.5638\n",
      "Epoch 14/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.5874 - acc: 0.6504 - val_loss: 0.7384 - val_acc: 0.5640\n",
      "Epoch 15/15\n",
      "242941/242941 [==============================] - 20s - loss: 0.5822 - acc: 0.6552 - val_loss: 0.7394 - val_acc: 0.5648\n",
      "242941/242941 [==============================] - 5s     \n"
     ]
    }
   ],
   "source": [
    "max_features = 15942 + 1\n",
    "batch_size = 3200\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 256, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2, consume_less='gpu'))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (242941, 20)\n",
      "X_test shape: (60736, 20)\n",
      "X_train[0]: [    0     0     0     0     0     0     0     0     0     0     0 10321\n",
      " 13493 12780 13735  5949 13172 15240 14262  2430]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_8 (Embedding)          (None, 20, 256)       4081408     embedding_input_8[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                    (None, 256)           525312      embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             257         lstm_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 1)             0           dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4606977\n",
      "____________________________________________________________________________________________________\n",
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6903 - acc: 0.5244 - val_loss: 0.6859 - val_acc: 0.5404\n",
      "Epoch 2/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6763 - acc: 0.5680 - val_loss: 0.6835 - val_acc: 0.5490\n",
      "Epoch 3/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6631 - acc: 0.5892 - val_loss: 0.6836 - val_acc: 0.5532\n",
      "Epoch 4/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6534 - acc: 0.6000 - val_loss: 0.6853 - val_acc: 0.5551\n",
      "Epoch 5/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6433 - acc: 0.6114 - val_loss: 0.6869 - val_acc: 0.5551\n",
      "Epoch 6/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6341 - acc: 0.6192 - val_loss: 0.6893 - val_acc: 0.5564\n",
      "Epoch 7/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6257 - acc: 0.6237 - val_loss: 0.6912 - val_acc: 0.5593\n",
      "Epoch 8/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6186 - acc: 0.6296 - val_loss: 0.6997 - val_acc: 0.5613\n",
      "Epoch 9/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6108 - acc: 0.6357 - val_loss: 0.7086 - val_acc: 0.5601\n",
      "Epoch 10/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.6041 - acc: 0.6401 - val_loss: 0.7100 - val_acc: 0.5613\n",
      "Epoch 11/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5975 - acc: 0.6443 - val_loss: 0.7176 - val_acc: 0.5619\n",
      "Epoch 12/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5921 - acc: 0.6488 - val_loss: 0.7284 - val_acc: 0.5645\n",
      "Epoch 13/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5854 - acc: 0.6534 - val_loss: 0.7341 - val_acc: 0.5641\n",
      "Epoch 14/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5803 - acc: 0.6583 - val_loss: 0.7416 - val_acc: 0.5659\n",
      "Epoch 15/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5743 - acc: 0.6637 - val_loss: 0.7410 - val_acc: 0.5662\n",
      "242941/242941 [==============================] - 8s     \n"
     ]
    }
   ],
   "source": [
    "max_features = 15942 + 1\n",
    "batch_size = 3200\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 256, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(256, dropout_W=0.2, dropout_U=0.2, consume_less='gpu'))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5686 - acc: 0.6677 - val_loss: 0.7542 - val_acc: 0.5676\n",
      "Epoch 2/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5624 - acc: 0.6736 - val_loss: 0.7689 - val_acc: 0.5696\n",
      "Epoch 3/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5566 - acc: 0.6778 - val_loss: 0.7698 - val_acc: 0.5717\n",
      "Epoch 4/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5521 - acc: 0.6821 - val_loss: 0.7742 - val_acc: 0.5714\n",
      "Epoch 5/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5470 - acc: 0.6862 - val_loss: 0.7780 - val_acc: 0.5726\n",
      "Epoch 6/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5405 - acc: 0.6920 - val_loss: 0.7881 - val_acc: 0.5748\n",
      "Epoch 7/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5358 - acc: 0.6958 - val_loss: 0.7922 - val_acc: 0.5749\n",
      "Epoch 8/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5311 - acc: 0.6998 - val_loss: 0.8150 - val_acc: 0.5779\n",
      "Epoch 9/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5263 - acc: 0.7035 - val_loss: 0.8010 - val_acc: 0.5786\n",
      "Epoch 10/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5221 - acc: 0.7072 - val_loss: 0.8255 - val_acc: 0.5790\n",
      "Epoch 11/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5187 - acc: 0.7100 - val_loss: 0.8152 - val_acc: 0.5782\n",
      "Epoch 12/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5134 - acc: 0.7151 - val_loss: 0.8287 - val_acc: 0.5802\n",
      "Epoch 13/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5100 - acc: 0.7182 - val_loss: 0.8298 - val_acc: 0.5800\n",
      "Epoch 14/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5048 - acc: 0.7211 - val_loss: 0.8436 - val_acc: 0.5819\n",
      "Epoch 15/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.5013 - acc: 0.7239 - val_loss: 0.8329 - val_acc: 0.5820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1625631b10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242941 samples, validate on 60736 samples\n",
      "Epoch 1/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4991 - acc: 0.7264 - val_loss: 0.8466 - val_acc: 0.5831\n",
      "Epoch 2/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4930 - acc: 0.7310 - val_loss: 0.8631 - val_acc: 0.5836\n",
      "Epoch 3/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4909 - acc: 0.7332 - val_loss: 0.8535 - val_acc: 0.5851\n",
      "Epoch 4/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4869 - acc: 0.7349 - val_loss: 0.8526 - val_acc: 0.5863\n",
      "Epoch 5/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4830 - acc: 0.7375 - val_loss: 0.8591 - val_acc: 0.5854\n",
      "Epoch 6/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4802 - acc: 0.7395 - val_loss: 0.8667 - val_acc: 0.5856\n",
      "Epoch 7/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4779 - acc: 0.7425 - val_loss: 0.8741 - val_acc: 0.5851\n",
      "Epoch 8/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4741 - acc: 0.7453 - val_loss: 0.8773 - val_acc: 0.5862\n",
      "Epoch 9/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4718 - acc: 0.7472 - val_loss: 0.8911 - val_acc: 0.5867\n",
      "Epoch 10/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4674 - acc: 0.7483 - val_loss: 0.8929 - val_acc: 0.5872\n",
      "Epoch 11/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4655 - acc: 0.7495 - val_loss: 0.8764 - val_acc: 0.5862\n",
      "Epoch 12/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4638 - acc: 0.7512 - val_loss: 0.8957 - val_acc: 0.5871\n",
      "Epoch 13/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4619 - acc: 0.7535 - val_loss: 0.8976 - val_acc: 0.5875\n",
      "Epoch 14/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4573 - acc: 0.7557 - val_loss: 0.9083 - val_acc: 0.5883\n",
      "Epoch 15/15\n",
      "242941/242941 [==============================] - 37s - loss: 0.4556 - acc: 0.7569 - val_loss: 0.9038 - val_acc: 0.5902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1625631710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title_stem</th>\n",
       "      <th>title_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>Alcoa (AA) to Shutter Pocos de Caldas Smelter ...</td>\n",
       "      <td>AA</td>\n",
       "      <td>alcoa aa shutter poco de calda smelter brazil ...</td>\n",
       "      <td>alcoa aa shutter pocos de caldas smelter brazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>Q2 Earnings Season in the Spotlight with Alcoa...</td>\n",
       "      <td>AA</td>\n",
       "      <td>q2 earn season spotlight alcoa report earn pre...</td>\n",
       "      <td>q2 earnings season spotlight alcoa report earn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>Earnings will be a nail biter: Jack Ablin</td>\n",
       "      <td>AA</td>\n",
       "      <td>earn nail biter jack ablin</td>\n",
       "      <td>earnings nail biter jack ablin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>3 Beaten-Down Stocks That May Pay Off for Cont...</td>\n",
       "      <td>AA</td>\n",
       "      <td>beaten stock may pay contrarian investor</td>\n",
       "      <td>beaten stock may pay contrarian investor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>UPDATE 1-Japan Q3 aluminium premiums mostly se...</td>\n",
       "      <td>AA</td>\n",
       "      <td>updat japan q3 aluminium premium mostli set ye...</td>\n",
       "      <td>update japan q3 aluminium premium mostly set y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        d1       d2        d3        date  \\\n",
       "0  2015-07-02 -0.006306  0.00272 -0.050633  2015-07-02   \n",
       "1  2015-07-02 -0.006306  0.00272 -0.050633  2015-07-02   \n",
       "2  2015-07-02 -0.006306  0.00272 -0.050633  2015-07-02   \n",
       "3  2015-07-02 -0.006306  0.00272 -0.050633  2015-07-02   \n",
       "4         NaN       NaN      NaN       NaN  2015-07-03   \n",
       "\n",
       "                                               title ticker  \\\n",
       "0  Alcoa (AA) to Shutter Pocos de Caldas Smelter ...     AA   \n",
       "1  Q2 Earnings Season in the Spotlight with Alcoa...     AA   \n",
       "2          Earnings will be a nail biter: Jack Ablin     AA   \n",
       "3  3 Beaten-Down Stocks That May Pay Off for Cont...     AA   \n",
       "4  UPDATE 1-Japan Q3 aluminium premiums mostly se...     AA   \n",
       "\n",
       "                                          title_stem  \\\n",
       "0  alcoa aa shutter poco de calda smelter brazil ...   \n",
       "1  q2 earn season spotlight alcoa report earn pre...   \n",
       "2                         earn nail biter jack ablin   \n",
       "3           beaten stock may pay contrarian investor   \n",
       "4  updat japan q3 aluminium premium mostli set ye...   \n",
       "\n",
       "                                           title_lem  \n",
       "0  alcoa aa shutter pocos de caldas smelter brazi...  \n",
       "1  q2 earnings season spotlight alcoa report earn...  \n",
       "2                     earnings nail biter jack ablin  \n",
       "3           beaten stock may pay contrarian investor  \n",
       "4  update japan q3 aluminium premium mostly set y...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = './data/news_o2.csv'\n",
    "df_all = pd.read_csv(fin,encoding='utf8')\n",
    "#df_all = df_all[df_all.target.notnull()]\n",
    "df_all['title_stem'] = apply_text_preprocessor(df_all['title'],str_stem)\n",
    "df_all['title_lem'] = apply_text_preprocessor(df_all['title'],str_lem)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origenal vocab: 24651\n",
      "transformed vocab: 9290\n"
     ]
    }
   ],
   "source": [
    "target = 'd1'\n",
    "\n",
    "df = df_all[df_all[target].notnull()]\n",
    "dftransformer =  DFtransformer(min_df=5)\n",
    "dftransformer.fit(df['title_lem'])\n",
    "seq_lst = dftransformer.tranform(df['title_lem'])\n",
    "maxlen = 20\n",
    "X = sequence.pad_sequences(seq_lst,maxlen=maxlen)\n",
    "y = (df[target].values>0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (86389, 20)\n",
      "X_test shape: (21598, 20)\n",
      "X_train[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  424 2569 5021 1320 3521]\n",
      "y_train[0]: 0\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_9 (Embedding)          (None, 20, 256)       2378496     embedding_input_9[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 256)           525312      embedding_9[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             257         lstm_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 1)             0           dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2904065\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 9290 + 1\n",
    "batch_size = 320\n",
    "\n",
    "for tr,va in StratifiedShuffleSplit(y,train_size=0.8,test_size=0.2,random_state=1024,n_iter=1):\n",
    "    X_train = X[tr]\n",
    "    y_train = y[tr]\n",
    "    X_test = X[va]\n",
    "    y_test = y[va]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_train[0]:',X_train[0])\n",
    "print('y_train[0]:',y_train[0])\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 256, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(256, dropout_W=0.2, dropout_U=0.2, consume_less='gpu'))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# for n in range(15):\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1,\n",
    "#               validation_data=(X_test, y_test),verbose=1)\n",
    "#     score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print()\n",
    "#     print('iter:',n+1)\n",
    "#     print('Train score:', score)\n",
    "#     print('Train accuracy:', acc)\n",
    "#     score, acc = model.evaluate(X_test, y_test,verbose=1,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=30,\n",
    "          validation_data=(X_test, y_test),verbose=1)\n",
    "score, acc = model.evaluate(X_train, y_train,verbose=1,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
